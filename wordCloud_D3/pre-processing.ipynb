{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get abstract\n",
    "df = pd.read_csv('result4.csv')\n",
    "df2 = df[['Abstract']]\n",
    "df2 = df2.dropna()\n",
    "abstract_string = df2['Abstract'].str.cat(sep=' ')\n",
    "abstract_string = abstract_string.replace(',','')\n",
    "abstract_string = abstract_string.replace('.','')\n",
    "abstract_string = abstract_string.replace('\"','')\n",
    "abstract_string = abstract_string.replace('(','')\n",
    "abstract_string = abstract_string.replace(')','')\n",
    "abstract_string = abstract_string.replace('!','')\n",
    "abstract_string = abstract_string.replace('?','')\n",
    "abstract_string = abstract_string.replace(':','')\n",
    "abstract_string = abstract_string.replace(';','')\n",
    "abstract_string = abstract_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read stopwords\n",
    "stopwords = pd.read_csv('stop_words.csv')\n",
    "sw = stopwords['a'].tolist()\n",
    "sw.append('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "abstract_string = ' '.join([word for word in abstract_string.split() if word not in sw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count\n",
    "word_count = Counter(abstract_string.split())\n",
    "word_count = pd.DataFrame.from_dict(word_count, orient='index').reset_index()\n",
    "word_count.columns = ['word', 'count']\n",
    "word_count = word_count.sort_values(by='count', ascending=False)\n",
    "word_count = word_count.reset_index(drop=True)\n",
    "# word_count.to_csv('word_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech language data results study model can using recognition used learning performance research method models paper based also proposed system different use features two children analysis training information neural methods show however noise approach speaker one network task voice communication work systems hearing social processing acoustic accuracy patients asr time compared text studies propose quality english first may deep audio new development word tasks hate participants speakers words three well present dataset significant test detection group signal automatic human languages rate improve perception found = better people emotion auditory article feature classification attention various clinical loss 2 experiments 1 including years process target age content significantly corpus across important findings high input linguistic without many evaluation signals level provide intelligibility showed purpose acts students framework will due media conditions context problem trained approaches novel set number control effect techniques sound differences measures experimental networks current types machine groups function frequency knowledge objective cognitive error support online related design enhancement understanding recent several production within datasets higher available algorithm ci natural effects role therapy assessment among previous multiple terms associated state-of-the-art applications visual treatment spoken whether existing translation scores large factors potential disorders temporal source demonstrate background users ability listening order main developed characteristics representations second technology individuals often 3 baseline best effective form interaction identify addition obtained result end-to-end ie outcomes conducted conclusions four improvement presented abstract health improved investigate speeches early need emotional domain adults skills listeners impact specific eg representation applied complex performed public strategies evidence aims even parameters evaluate memory future tts intervention discourse focus limited synthesis brain given thus achieved low range architecture individual common practice technique sentences speech-language suggest part review political achieve levels mean activity speaking challenge samples motor shown response case less included act changes score evaluated education responses observed reported algorithms disease provides utterances structure overall especially similar respectively problems uses aim relative literature application type field increased therefore help noisy covid-19 reading life general patterns vocal although single analyzed semantic convolutional p average identification finally shows way like possible cochlear make collected functions environment experience standard still sentence disorder challenges effectiveness state following video pitch separation challenging considered relationship increase conclusion investigated explore positive particular qualitative furthermore care via identified find lexical made prediction theory emotions output traditional influence reduction key devices revealed n condition address achieves sounds experiment errors aphasia designed presents recordings modeling spectral normal months extraction user specifically gender develop since patient lower total perform primary perceptual extracted recently measure known according functional aspects strategy change provided real duration oral recorded power phonetic subjects produced moreover good style transfer outperforms describe researchers negative area music services tests issues generate additional db determine examined image learn encoder small l2 understand measured cases impairment correlation prosody native 4 able subjective child forms communicative either analyze generated difficulties means diagnosis robust spatial â€“ prosodic database scale components demonstrated sample conventional slps long stimuli environments sequence teaching us critical reduce tool face analyses adaptation community difference world cues mechanism directly space behavior questions five examine tested generation developing train improvements presence compare indicate importance needs 10 lack expressive relevant embedding gestures utterance ratio phonological digital adversarial namely testing aimed older regarding issue original size become access phase pre-trained pd areas direct cnn module complexity implications transformer highly values yet school chinese increasing comparison symptoms meaning include material combination introduce assess prior perceived global risk variability much detect conversion linear assessed processes stage 2020 despite 20 particularly wer pronunciation technologies resources implementation working towards amount proposes verbal 5 survey vowel reference sources improves multimodal distribution reduced predict embeddings vocabulary comprehension multilingual short rehabilitation expression benefit extract spectrum computational combined simple texts interactions strong improving greater medical young along difficult accurate rates variety pathology selected categories settings pandemic widely units artificial typically required hand affect corpora tools classifier local nature mechanisms effectively teachers called certain carried conversational scenarios text-to-speech metrics educational feedback report ser adult articulation selection goal 6 allows modern major account outcome inference mental facial obtain physical setting recurrent efficient requires works identity corresponding augmentation right useful learners employed asd promising domains free dynamic activities regression healthy discussed snr eeg spontaneous abilities question & states university professional severity value service developmental real-time written descriptive estimation sets pathologists stuttering example arabic population vector discuss search practical person six essential movements practices affected decoding consider might interventions end interest russian received basis layers making degree cortical component behavioral contrast statistical produce female focused implemented severe studied consists completed pragmatic dysarthria shared parents ways includes\n"
     ]
    }
   ],
   "source": [
    "#get first 100 words\n",
    "word_count = word_count.head(750)\n",
    "word_list = word_count['word'].tolist()\n",
    "wl = ' '.join(word_list)\n",
    "print(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_string = ' '.join([word for word in abstract_string.split() if word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to txt\n",
    "with open('word_string.txt', 'w') as f:\n",
    "    f.write(word_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the first 100 words\n",
    "word_count = word_count.head(750)\n",
    "word_count.to_csv('word_count_750.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a json file for d3\n",
    "word_count = word_count.set_index('word')\n",
    "word_count.to_json('word_count.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "csv_file = \"word_count_750.csv\"\n",
    "json_file = \"word_count_750.json\"\n",
    "\n",
    "# Read CSV file into a list of dictionaries\n",
    "with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    rows = [row for row in reader]\n",
    "\n",
    "# Convert list of dictionaries to list of objects in desired format size in the format of string\n",
    "myWords = [{\"name\": row[\"word\"], \"value\": row[\"count\"]} for row in rows]\n",
    "# Write list of objects to JSON file\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(myWords, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '123.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ts/yc6c7tl96hjdf33yyy_9y96m0000gn/T/ipykernel_84645/929901514.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'123.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#convert it to base64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '123.png'"
     ]
    }
   ],
   "source": [
    "#read 123.png\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open('123.png')\n",
    "\n",
    "#convert it to base64\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "buffered = BytesIO()\n",
    "img.save(buffered, format=\"PNG\")\n",
    "img_str = base64.b64encode(buffered.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "399d0e3137bfbbe732ffce16f404d0134f25670dcd6d6cdc60d5d201443092cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
