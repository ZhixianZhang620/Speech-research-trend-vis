{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From CSV to SigmaJS\n",
    "## Creating a Social Network Graph of the Marvel Universe\n",
    "\n",
    "\n",
    "This notebooks converts a CSV-file containing a information on Co-Occurences of Marvel Superheroes [see data source](https://www.kaggle.com/csanhueza/the-marvel-universe-social-network/code) into a SigmaJS graph.\n",
    "\n",
    "* **Author:** Tim Denzler, Yueqian Lin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create an empty networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph() #empty networkx graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read the CSV file and generate the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/result_with_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "new_df = pd.DataFrame(columns=['Author 1', 'Author 2'])\n",
    "for index, row in df.iterrows():\n",
    "    authors = row['Author Name']\n",
    "    if isinstance(authors, str) and authors.strip() != \"\":\n",
    "        authors = authors.split(', ')\n",
    "        for author1, author2 in combinations(authors, 2):\n",
    "            new_df = new_df.append({'Author 1': author1, 'Author 2': author2}, ignore_index=True)\n",
    "\n",
    "# Save the new dataframe to a CSV file\n",
    "new_df.to_csv('output_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14665it [00:00, 254441.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define minimum degree for nodes\n",
    "min_degree = 0\n",
    "\n",
    "# Create empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Read data from CSV file and add nodes and edges\n",
    "with open('output_filtered.csv', 'r') as f:\n",
    "    data = csv.reader(f)\n",
    "    headers = next(data)\n",
    "    for row in tqdm(data):\n",
    "        G.add_node(row[0]) #superhero in first column\n",
    "        G.add_node(row[1]) #superhero in second column\n",
    "        if G.has_edge(row[0], row[1]):\n",
    "            # edge already exists, increase weight by one\n",
    "            G[row[0]][row[1]]['weight'] += 1\n",
    "        else:\n",
    "            # add new edge with weight 1\n",
    "            G.add_edge(row[0], row[1], weight = 1)\n",
    "\n",
    "# Remove nodes with degree less than min_degree\n",
    "for node in list(G.nodes()):\n",
    "    if G.degree(node) < min_degree:\n",
    "        G.remove_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "import community  # pip install python-louvain\n",
    "\n",
    "# Read data from CSV file and add nodes and edges\n",
    "G = nx.Graph()\n",
    "with open('output_file.csv', 'r') as f:\n",
    "    data = csv.reader(f)\n",
    "    headers = next(data)\n",
    "    for row in data:\n",
    "        G.add_edge(row[0], row[1])\n",
    "\n",
    "# Apply Louvain algorithm for community detection\n",
    "partition = community.best_partition(G)\n",
    "\n",
    "# Filter nodes by modularity\n",
    "modularity_threshold = 0.1\n",
    "for node in list(G.nodes()):\n",
    "    if partition[node] == -1:\n",
    "        G.remove_node(node)\n",
    "    else:\n",
    "        node_modularity = len([n for n in G.neighbors(node) if partition[n] != partition[node]])\n",
    "        node_modularity /= G.degree(node) if G.degree(node) > 0 else 1  # Check for zero degree\n",
    "        if node_modularity < modularity_threshold:\n",
    "            G.remove_node(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "559273it [00:01, 295495.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define minimum degree for nodes\n",
    "min_degree = 15\n",
    "\n",
    "# Create empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Read data from CSV file and add nodes and edges\n",
    "with open('output_file.csv', 'r') as f:\n",
    "    data = csv.reader(f)\n",
    "    headers = next(data)\n",
    "    for row in tqdm(data):\n",
    "        author1 = row[0].rstrip(',')\n",
    "        author2 = row[1].rstrip(',')\n",
    "        G.add_node(author1)\n",
    "        G.add_node(author2)\n",
    "        if G.has_edge(author1, author2):\n",
    "            # edge already exists, increase weight by one\n",
    "            G[author1][author2]['weight'] += 1\n",
    "        else:\n",
    "            # add new edge with weight 1\n",
    "            G.add_edge(author1, author2, weight = 1)\n",
    "\n",
    "# Remove nodes with degree less than min_degree\n",
    "for node in list(G.nodes()):\n",
    "    if G.degree(node) < min_degree:\n",
    "        G.remove_node(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes =  3297  Edges =  8781\n"
     ]
    }
   ],
   "source": [
    "G_nodes = G.number_of_nodes()\n",
    "G_edges = G.number_of_edges()\n",
    "print(\"Nodes = \", G_nodes, \" Edges = \",G_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Store the graph in gexf-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvelgraph = nx.write_gexf(G, \"./data/result_filter_100.gexf\") #save for gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2676c0d50d021c0ab6745578d37607fe06a9d78dd74021a4811f6c590724974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
